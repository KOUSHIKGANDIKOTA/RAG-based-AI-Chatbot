# ğŸ¤– RAG Chatbot with FAISS and LLaMA

A **Retrieval-Augmented Generation (RAG)** chatbot that allows you to upload PDFs and ask questions about their content.  
It uses **LangChain, HuggingFace embeddings, FAISS vector database, and Ollamaâ€™s LLaMA model** to build a local AI-powered knowledge assistant with an easy-to-use **Streamlit** interface.

---

## ğŸ§  How RAG Works

---

**Retrieval-Augmented Generation (RAG)** is a technique that improves large language models (LLMs) by combining them with external knowledge sources.
## âœ¨ Features
- ğŸ“„ Upload **PDF documents** and extract their text
- ğŸ§© Split documents into chunks for better context handling
- ğŸ” Store & retrieve text using **FAISS** vector database
- ğŸ§  Answer questions with **LLaMA (via Ollama)**
- ğŸŒ Simple & interactive **Streamlit UI**
- âš¡ Runs **locally** â€” no external API calls needed

---


Hereâ€™s how this project implements RAG:

**Step-by-step workflow:**
1. **Extract PDF Text** â†’ Convert uploaded PDF into raw text.  
2. **Chunking** â†’ Split text into manageable chunks.  
3. **Embeddings** â†’ Encode chunks using HuggingFace models.  
4. **Store in FAISS** â†’ Save embeddings in a vector database for similarity search.  
5. **Retrieve** â†’ Fetch the most relevant chunks for a query.  
6. **Generate Answer** â†’ LLaMA uses the retrieved context to generate accurate responses.

This ensures the chatbot **grounds its answers in the actual document**, rather than hallucinating.
